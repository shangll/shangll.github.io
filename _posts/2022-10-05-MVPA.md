---
title: 'Decoding/MVPA - ML'
date: 2022-10-05
permalink: /posts/2025/06/MVPA/
tags:
  - python
  - Decoding
  - MVPA
  - ML
---

*注：本文基于Bae 2018年J. Neurosci上的这篇Dissociable Decoding of Spatial Attention and Working Memory from EEG Oscillations and Sustained Potentials，强烈建议阅读原文。*
*本文是仅针对懂EEG和fMRI实验并有处理经验、但无decoding经验的读者撰写的说明书；如无相关经验，不建议阅读，也不建议联系本文作者（谢谢！！！）*

#结尾有彩蛋

**Decoding在做什么、怎么做？**

人们在看不同类别图片的时候，大脑是有不同的反应模式的。如果大脑encode了这种刺激，两个种类的刺激的活动应该是不一样的。如果有一个很好的classifier，那么这两种不一样的活动就会被分类出来（所以这里我们可以看出来，decoding本质上就是在做representations）。比如我1个session 8个run，就可以training前7个run去test最后1个run。Decoding似乎fMRI用的比较早（不确定，印象中是这样），那时候还叫MVPA。这俩本质上是一个东西。那个V就是voxel的意思，到EEG中就变成了time course。如果EEG不叫decoding，那就得叫MTPA。仅此而已。

***Interim Summary***：decoding的核心原理就是我有一堆data。这堆data是二元（或者多元也行）可分的。我可以从中分出一大部分，用一个很好的classifier去training data怎么去分类，然后用trained data去test剩下的data。就是这么简单。

**下一个问题就是怎么做decoding？**

首先我们loading data：

```
import mne
epochs = mne.read_epochs('preprocessed_epochs_1.fif')
subj_data = epochs.get_data()
# data structure: 640 trials * 27 channels * 750 times
```

Bae这一篇是每个trial有750个time points，每个被试做了640个trials，decode 27个channels。Decoding可以ERP based也可以band power based。Bae两个都做了，我这里只展示ERP based，因为步骤都一样。我们先对已经loaded的subject 1做decoding。这里插播一个步骤**crop data**，也就是选取特定的time window。这一步不是强制的，但非常推荐。为啥？因为我们是针对time point解码。现在，我们手上的数据是250 Hz的，也就是1个时间点对应0.004"，750个time points就是3"。Bae文章中写了是onset前后1.5"。假设我们只关注1"前后，我们可以选0到1.5这个范围。相当于把baseline给剔除了。我们不做crop的话，就是把这3"全喂进去decode，效果肯定不如只做0-1.5这一段的。

```
```

```
# down sample
def resamp_t(data):
    data_avg_t = np.zeros([data.shape[0],
                           data.shape[1],
                           data.shape[2]])
    for t in range(t_points):
        data_avg_t[:,:,t] = np.average(
                data[:,:,t*t_space:t*t_space+t_space],
                axis=2)
    return data_avg_t
```











